{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8024a2d4-d540-4e8a-8fd9-c00f3e4f7357",
   "metadata": {},
   "source": [
    "# Ejemplo archivos\n",
    "1. Creamos a SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facda3fa-731d-49b7-a68f-b37e43dd6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hadoop/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hadoop/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.kafka#kafka-clients added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ed7044ec-fc8c-4b26-b88f-047623f62f6c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.5.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.5.5-1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      ":: resolution report :: resolve 2365ms :: artifacts dl 178ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.5.5-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   3   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ed7044ec-fc8c-4b26-b88f-047623f62f6c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/212ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de spark:  3.5.7\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "import string\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "  .appName(\"arquivo-example-1\")\\\n",
    "  .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "print(\"Versión de spark: \",spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb0387-afa8-4487-8e72-2b3a24f94f72",
   "metadata": {},
   "source": [
    "2. Obtéñese o esquema e indícase a orixe dos datos para o procesamento en *streaming*, neste caso un cartafol con ficheiros *json*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cdfd0a-2edd-45e8-86a7-5eaceb7ed76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defínese a ruta onde se atopan os ficheiros JSON cos datos de entrada\n",
    "path = \"/data/flight-data/json\"\n",
    "\n",
    "# Lense os datos de forma estática para obter o esquema\n",
    "static = spark.read.json(path)\n",
    "\n",
    "# Extráese o esquema do DataFrame estático\n",
    "dataSchema = static.schema\n",
    "\n",
    "# Créase un DataFrame de streaming usando o esquema obtido previamente\n",
    "# maxFilesPerTrigger = 1 indica que se procesará como máximo un ficheiro novo en cada micro-batch\n",
    "streaming = spark.readStream \\\n",
    "    .schema(dataSchema) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .json(path)\n",
    "\n",
    "# Móstrase o esquema do DataFrame de streaming\n",
    "streaming.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb56dc-a4c7-4804-b7f7-7286cd88f336",
   "metadata": {},
   "source": [
    "3. Obtense o DataFrame de saída transformando os datos iniciais. Neste caso agrúpase por *DEST_COUNTRY_NAME* e cóntase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47700da-b15d-41dd-ae1e-df7509b92833",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = streaming.groupBy(\"DEST_COUNTRY_NAME\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a8594-8643-40d4-9af2-f504b01445f3",
   "metadata": {},
   "source": [
    "4. Iniciamos o procesamento en streaming con saída a memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc2c437-554f-47fd-9859-f91a64c2e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:================================================>        (54 + 1) / 64]"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    counts.writeStream\n",
    "        # Asígnase un nome á consulta\n",
    "        .queryName(\"counts\")\n",
    "        # Indícase que a saída se gardará en memoria\n",
    "        .format(\"memory\")\n",
    "        # Escríbese o resultado completo en cada micro-batch\n",
    "        .outputMode(\"complete\")\n",
    "        # Iníciase a consulta de streaming\n",
    "        .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941aab47-3820-411c-975c-f887c2a76464",
   "metadata": {},
   "source": [
    "5. Mostramos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94b54e0-ca04-4455-b2c8-cb56838bf7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:===================================================>     (58 + 1) / 64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|count|\n",
      "+--------------------+-----+\n",
      "|           Nicaragua|    1|\n",
      "|         South Korea|    1|\n",
      "|   Equatorial Guinea|    1|\n",
      "|          Guadeloupe|    1|\n",
      "|           Australia|    1|\n",
      "|       French Guiana|    1|\n",
      "|              Turkey|    1|\n",
      "|         The Bahamas|    1|\n",
      "|Netherlands Antilles|    1|\n",
      "|             Bermuda|    1|\n",
      "| Antigua and Barbuda|    1|\n",
      "|             Denmark|    1|\n",
      "|               Samoa|    1|\n",
      "|         Switzerland|    1|\n",
      "| Trinidad and Tobago|    1|\n",
      "|             Vietnam|    1|\n",
      "|         Philippines|    1|\n",
      "|               Palau|    1|\n",
      "|             Belgium|    1|\n",
      "|           Hong Kong|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|count|\n",
      "+--------------------+-----+\n",
      "|   Equatorial Guinea|    1|\n",
      "|           Nicaragua|    2|\n",
      "|         South Korea|    2|\n",
      "|                Togo|    1|\n",
      "|          Guadeloupe|    2|\n",
      "|           Australia|    2|\n",
      "|       French Guiana|    2|\n",
      "|             Romania|    1|\n",
      "|              Turkey|    2|\n",
      "|         The Bahamas|    2|\n",
      "|Netherlands Antilles|    1|\n",
      "|             Bermuda|    2|\n",
      "| Antigua and Barbuda|    2|\n",
      "|             Denmark|    2|\n",
      "|               Samoa|    2|\n",
      "|         Switzerland|    2|\n",
      "|             Vietnam|    2|\n",
      "| Trinidad and Tobago|    2|\n",
      "|         Philippines|    2|\n",
      "|               Palau|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|count|\n",
      "+--------------------+-----+\n",
      "|   Equatorial Guinea|    1|\n",
      "|           Nicaragua|    3|\n",
      "|         South Korea|    3|\n",
      "|                Togo|    1|\n",
      "|            Cameroon|    1|\n",
      "|          Guadeloupe|    3|\n",
      "|           Australia|    3|\n",
      "|       French Guiana|    3|\n",
      "|             Romania|    1|\n",
      "|              Turkey|    3|\n",
      "|         The Bahamas|    3|\n",
      "|Netherlands Antilles|    1|\n",
      "|             Bermuda|    3|\n",
      "| Antigua and Barbuda|    3|\n",
      "|             Denmark|    3|\n",
      "|               Samoa|    3|\n",
      "|         Switzerland|    3|\n",
      "|             Vietnam|    3|\n",
      "| Trinidad and Tobago|    3|\n",
      "|         Philippines|    3|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|count|\n",
      "+--------------------+-----+\n",
      "|   Equatorial Guinea|    2|\n",
      "|           Nicaragua|    4|\n",
      "|         South Korea|    4|\n",
      "|                Togo|    1|\n",
      "|            Cameroon|    1|\n",
      "|          Guadeloupe|    4|\n",
      "|           Australia|    4|\n",
      "|       French Guiana|    4|\n",
      "|           Indonesia|    1|\n",
      "|             Romania|    2|\n",
      "|              Turkey|    4|\n",
      "|         The Bahamas|    4|\n",
      "|Netherlands Antilles|    1|\n",
      "|             Bermuda|    4|\n",
      "| Antigua and Barbuda|    4|\n",
      "|             Denmark|    4|\n",
      "|              Rwanda|    1|\n",
      "|               Samoa|    4|\n",
      "|         Switzerland|    4|\n",
      "|             Vietnam|    3|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "for x in range(5):\n",
    "    spark.sql(\"SELECT * FROM counts\").show()\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed346219-a94b-4622-95e8-a7ffe176b0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
