{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352e2261-fe11-4ec3-9c54-c0f12c6a1d04",
   "metadata": {},
   "source": [
    "# Exemplo ventás 1\n",
    "En primeiro lugar iniciamos a sesión como nos casos anteriores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f6d15a-73d2-410d-bf1a-c83036fb8a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hadoop/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hadoop/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.kafka#kafka-clients added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a2f1420d-64dd-4f78-8350-84e8627746be;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.5.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.5.5-1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      ":: resolution report :: resolve 1798ms :: artifacts dl 64ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.5.5-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   3   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a2f1420d-64dd-4f78-8350-84e8627746be\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/72ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión:  3.5.7\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "import string\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Windows\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Versión: \",spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a527b8-8a1f-49c1-b27e-b449b522dab4",
   "metadata": {},
   "source": [
    "Neste exemplo imos ler, de novo, os datos desde un *socket*. Antes de nada póñese en marcha co seguinte comando:\n",
    "```bash\n",
    "nc -lk 9999\n",
    "```\n",
    "\n",
    "O seguinte paso é poñer en marcha o *stream* de lectura, nesta ocasión activando a opción *includeTimestamp*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff106b3-a4d1-4222-aae8-e35b1e56581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lineas = spark.readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", \"9999\") \\\n",
    "    .option('includeTimestamp', 'true')\\\n",
    "    .load()\n",
    "\n",
    "df_lineas.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbbf5ab-6635-45db-96c7-01fe7ad9d09c",
   "metadata": {},
   "source": [
    "Do mesmo xeito que no exemplo orixinal do *socket*, imos facer un *wordcount*; a diferenza é que neste caso inclúese o *timestamp*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6447b213-0151-48ae-a1f5-b020dbaffad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "df_palabras = df_lineas.select(\n",
    "    explode(split(df_lineas.value, ' ')).alias('palabra'),\n",
    "    df_lineas.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc0841-0fee-4cc7-b967-6942332d3164",
   "metadata": {},
   "source": [
    "Créase unha xanela fixa de dous minutos. Isto agrupará os datos, palabra e reconto, por períodos fixos de tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe1a2f5-39f8-4071-9098-5caad3dad07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- palabra: string (nullable = false)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import window\n",
    "windowed_counts = df_palabras.groupBy(\n",
    "    window(df_palabras.timestamp, \"2 minutes\"), df_palabras.palabra\n",
    ").count().orderBy('window')\n",
    "\n",
    "windowed_counts.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9176d8-10a5-4bd3-a8e4-28ea7394b1e8",
   "metadata": {},
   "source": [
    "Realízase a consulta indicando como *sink* a consola. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1ccb4c-1816-47d9-8e07-9f948d0e7ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------+-------+-----+\n",
      "|window|palabra|count|\n",
      "+------+-------+-----+\n",
      "+------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |palabra |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|y       |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|hasta   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|el      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|probando|2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|no      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|cuando  |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mazo    |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|dando   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|con     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|se      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mola    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |palabra |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|y       |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|hasta   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|nada    |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|el      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mas     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|probando|2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|no      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|cuando  |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mazo    |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|dando   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|con     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|se      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mola    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |palabra |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|y       |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|hasta   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|nada    |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|el      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mas     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|probando|2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|no      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|cuando  |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mazo    |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|dando   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|con     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|se      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mola    |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|probando|1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|mazo    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |palabra |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|y       |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|hasta   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|nada    |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|el      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mas     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|probando|2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|no      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|cuando  |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mazo    |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|dando   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|con     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|se      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mola    |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|probando|1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|mola    |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|mazo    |2    |\n",
      "+------------------------------------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |palabra |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|y       |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|hasta   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|nada    |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|el      |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mas     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|probando|2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|no      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|cuando  |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mazo    |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|dando   |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|con     |1    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|se      |2    |\n",
      "|{2026-02-09 18:20:00, 2026-02-09 18:22:00}|mola    |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|probando|1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|mola    |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|ola     |1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|caracola|1    |\n",
      "|{2026-02-09 18:22:00, 2026-02-09 18:24:00}|mazo    |2    |\n",
      "+------------------------------------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = windowed_counts \\\n",
    "          .writeStream \\\n",
    "          .outputMode(\"complete\") \\\n",
    "          .format(\"console\") \\\n",
    "          .queryName(\"consulta1\") \\\n",
    "          .option(\"truncate\",\"false\") \\\n",
    "          .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c9ba7-33aa-41c5-ad53-34b025f0dff9",
   "metadata": {},
   "source": [
    "> Como se pode observar, as agregacións vanse realizando por ventás de dous minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55081a-0771-48e6-bfd0-9ecff3ffd08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
