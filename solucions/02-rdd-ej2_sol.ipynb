{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f57987d-a229-486b-8556-9d01504e4aa1",
   "metadata": {},
   "source": [
    "# Ejercicios RDD de pares\n",
    "1. Inicia las variables SparkSession y SparkContext (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9b91cb-568c-48ae-b033-18bd92eb18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hadoop/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hadoop/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.kafka#kafka-clients added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4b59fdc3-3f3b-4053-96b8-156a18317b9e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.5.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.5.5-1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      ":: resolution report :: resolve 282ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.5.5-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.7 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   3   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4b59fdc3-3f3b-4053-96b8-156a18317b9e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/10ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 50786)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inicializamos SparkSession y SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"02-rddej2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "print(spark.version)  # Verifica la versión de Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0f810-ba11-481f-a22c-0204752702a8",
   "metadata": {},
   "source": [
    "2. Crea un rdd de pares da forma (palabra, 1) a partir do ficheiro /data/el_quijote.txt (0,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087896ff-3e79-48bc-afb4-210f9b237064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('DON', 1),\n",
       " ('QUIJOTE', 1),\n",
       " ('DE', 1),\n",
       " ('LA', 1),\n",
       " ('MANCHA', 1),\n",
       " ('Miguel', 1),\n",
       " ('de', 1),\n",
       " ('Cervantes', 1),\n",
       " ('Saavedra', 1),\n",
       " ('PRIMERA', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) RDD de pares (palabra, 1) a partir de data/el_quijote.txt\n",
    "\n",
    "rdd_palabras_1 = (\n",
    "    sc.textFile(\"/data/el_quijote.txt\")\n",
    "      .flatMap(lambda liña: liña.split())\n",
    "      .map(lambda palabra: (palabra, 1))\n",
    ")\n",
    "\n",
    "rdd_palabras_1.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c9b12-89de-4306-a400-3e4c2dcafce0",
   "metadata": {},
   "source": [
    "3. A partir do RDD anterior, conta o número de aparicións de cada palabra (0,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cee66f5-464c-452c-b3d5-fe72d00c6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('DE', 17),\n",
       " ('LA', 13),\n",
       " ('Miguel', 3),\n",
       " ('PRIMERA', 1),\n",
       " ('CAPÍTULO', 1),\n",
       " ('1:', 1),\n",
       " ('condición', 23),\n",
       " ('y', 8042),\n",
       " ('del', 1113),\n",
       " ('hidalgo', 16)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Contar o número de aparicións de cada palabra a partir de (palabra, 1)\n",
    "rdd_conta_palabras = rdd_palabras_1.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "rdd_conta_palabras.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef2c56-ca9d-4cde-8714-12b7b02a7b87",
   "metadata": {},
   "source": [
    "4. Repite os exercicios 2 e 3 de xeito que non se teñan en conta os signos de puntuación e non se distingan maiúsculas de minúsculas (mapea todo a minúsculas) (0,25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f221d6-54f7-44dc-968c-73ed113051ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 3159),\n",
       " ('s', 1571),\n",
       " ('mis', 171),\n",
       " ('alabanzas', 13),\n",
       " ('don', 1088),\n",
       " ('porque', 772),\n",
       " ('nero', 30),\n",
       " ('adulacio', 2),\n",
       " ('y', 8690),\n",
       " ('lo', 1945)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 4) Repetir 2 e 3 ignorando puntuación e sen distinguir maiúsculas/minúsculas\n",
    "rdd_palabras_1_limpo = (\n",
    "    sc.textFile(\"/data/el_quijote.txt\")\n",
    "      .flatMap(lambda liña: re.findall(r\"[a-záéíóúüñ]+\", liña.lower()))\n",
    "      .map(lambda palabra: (palabra, 1))\n",
    ")\n",
    "\n",
    "rdd_conta_palabras_limpo = rdd_palabras_1_limpo.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "rdd_conta_palabras_limpo.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14a42c-e834-42ec-b86e-74bd45ae11a5",
   "metadata": {},
   "source": [
    "5. Agregacións.\n",
    "   - a) `keyBy`: rear rdd_inicial onde a clave sexa a primeira letra de cada palabra de rdd_texto (0,5).\n",
    "   - b)Partindo de `rdd_inicial` (1):\n",
    "     - Converter o valor (palabra) a **maiúsculas** usando `mapValues`.\n",
    "     - Crear outro RDD onde o valor sexa a **lonxitude** da palabra, mantendo a mesma clave.\n",
    "   - c) `keys`: Obter as claves distintas de `rdd_inicial`(0,5)\n",
    "   - d) `values`: Obter cantos valores distintos hai en `rdd_inicial` (0,5).\n",
    "   - e) `sample_by_key` (1):\n",
    "     - En `rdd_inicial`, tomar unha mostra do **80%** das palabras que comezan por `'d'` e **20%** das que comezan por `'l'`.\n",
    "     - Evitar `KeyError` asegurando que o diccionario `fractions` inclúe **todas as claves** (as non usadas deben ter 0.0).\n",
    "   - f) `countByKey`: contar elementos por clave de `rdd_inicial` (0,5).\n",
    "   - g) `aggregate`: sobre `rdd_texto` (1):\n",
    "     -   Calcula nunha soa pasada `(n_palabras, suma_caracteres)`.\n",
    "     -   Obtén a `lonxitude_media`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f27b57-1ede-4c34-9933-6e0b8fba3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset base para todo o laboratorio\n",
    "# (executar esta celda antes de comezar cos exercicios)\n",
    "\n",
    "# 1) Texto (para keyBy / mapValues / reduceByKey...)\n",
    "texto = \"\"\"En un lugar de la Mancha de cuyo nombre no quiero acordarme\n",
    "no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero\n",
    "adarga antigua rocín flaco y galgo corredor\"\"\"\n",
    "rdd_texto = sc.parallelize(texto.lower().split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca5d087-2d0b-44f2-81e4-b7e0c92bea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 'en'),\n",
       " ('u', 'un'),\n",
       " ('l', 'lugar'),\n",
       " ('d', 'de'),\n",
       " ('l', 'la'),\n",
       " ('m', 'mancha'),\n",
       " ('d', 'de'),\n",
       " ('c', 'cuyo'),\n",
       " ('n', 'nombre'),\n",
       " ('n', 'no')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a\n",
    "rdd_inicial = rdd_texto.keyBy(lambda w: w[0])\n",
    "rdd_inicial.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47934342-11ae-416a-a8cb-ffb60e30cf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('e', 'EN'), ('u', 'UN'), ('l', 'LUGAR'), ('d', 'DE'), ('l', 'LA')],\n",
       " [('e', 2), ('u', 2), ('l', 5), ('d', 2), ('l', 2)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "rdd_inicial_upper = rdd_inicial.mapValues(lambda w: w.upper())\n",
    "rdd_inicial_len = rdd_inicial.mapValues(lambda w: len(w))\n",
    "rdd_inicial_upper.take(5), rdd_inicial_len.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fed352-6882-48c9-a92a-0844d9ad2cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l',\n",
       " 'd',\n",
       " 'c',\n",
       " 'h',\n",
       " 'r',\n",
       " 'y',\n",
       " 'g',\n",
       " 'q',\n",
       " 'v',\n",
       " 'u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'f',\n",
       " 'm',\n",
       " 'n',\n",
       " 't']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "claves_distintas = rdd_inicial.keys().distinct().collect()\n",
    "claves_distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5f0e7a-f7d5-456e-92f2-cb2e7fd95a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d\n",
    "n_valores_distintos = rdd_inicial.values().distinct().count()\n",
    "n_valores_distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e422b691-40bc-4095-9dce-dc8f14db470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', 'de'), ('l', 'la'), ('d', 'de'), ('d', 'de'), ('l', 'lanza')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e\n",
    "keys = rdd_inicial.keys().distinct().collect()\n",
    "fractions = {k: 0.0 for k in keys}\n",
    "fractions['d'] = 0.8\n",
    "fractions['l'] = 0.2\n",
    "mostra = rdd_inicial.sampleByKey(False, fractions, seed=42)\n",
    "mostra.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55b5dc3-9286-4007-8828-326108212f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'e': 2,\n",
       "             'u': 2,\n",
       "             'l': 4,\n",
       "             'd': 4,\n",
       "             'm': 2,\n",
       "             'c': 2,\n",
       "             'n': 3,\n",
       "             'q': 2,\n",
       "             'a': 4,\n",
       "             'h': 2,\n",
       "             't': 1,\n",
       "             'v': 1,\n",
       "             'r': 1,\n",
       "             'f': 1,\n",
       "             'y': 1,\n",
       "             'g': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f\n",
    "conta_por_clave = rdd_inicial.countByKey()\n",
    "conta_por_clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0fbcdf-6ad9-4835-9f55-fd2ee8ad9f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 140, 4.242424242424242)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g\n",
    "zero = (0, 0)\n",
    "\n",
    "def seqOp(acc, w):\n",
    "    return (acc[0] + 1, acc[1] + len(w))\n",
    "\n",
    "def combOp(a, b):\n",
    "    return (a[0] + b[0], a[1] + b[1])\n",
    "\n",
    "n_palabras, suma_caracteres = rdd_texto.aggregate(zero, seqOp, combOp)\n",
    "lonxitude_media = suma_caracteres / n_palabras if n_palabras else 0\n",
    "\n",
    "(n_palabras, suma_caracteres, lonxitude_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5279c8-2a9f-4ab1-82c0-136f280b2eb2",
   "metadata": {},
   "source": [
    "6. A partir de los ficheros /data/notas/notas_mates.txt, /data/notas/notas_fisica.txt y /data/notas/notas_ingles.txt, realiza las siguientes operaciones:\n",
    "   - a) Crea 3 RDD de pares uno para cada asignatura (notas_mates, notas_ingles, notas_fisica) (0,5)\n",
    "   - b) Crea un RDD que sea la unión de los 3 anteriores (0,5)\n",
    "   - c) Muestra la nota más baja de cada alumno (0,5)\n",
    "   - d) Muestra la nota media de cada alumno (0,5)\n",
    "   - e) Muestra cuantos estudiantes suspenden cada asignatura (0,5)\n",
    "   - f) Muestra en qué asignatura suspende más gente (0,5)\n",
    "   - g) Obtén un RDD que que asocie a cada alumno con las notas en todas las asignaturas (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d940f3-8d71-4bb3-b2cf-7e7ae711e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Angel', 4.0),\n",
       " ('Maria', 6.0),\n",
       " ('Ramon', 8.0),\n",
       " ('Jorge', 5.0),\n",
       " ('Susana', 2.0),\n",
       " ('Anabel', 7.0),\n",
       " ('Rocio', 4.0),\n",
       " ('Carlos', 8.0),\n",
       " ('Triana', 4.0),\n",
       " ('Andres', 6.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "parse_nota = lambda linea: (linea.split(',')[0], float(linea.split(',')[1]))\n",
    "notas_mates  = sc.textFile(\"/data/notas/notas_mates.txt\").map(parse_nota)\n",
    "notas_fisica = sc.textFile(\"/data/notas/notas_fisica.txt\").map(parse_nota)\n",
    "notas_ingles = sc.textFile(\"/data/notas/notas_ingles.txt\").map(parse_nota)\n",
    "notas_ingles.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b008dd84-05ca-486b-a251-b80a68c521b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Angel', 6.0),\n",
       " ('Maria', 2.0),\n",
       " ('Ramon', 4.5),\n",
       " ('Jorge', 10.0),\n",
       " ('Susana', 9.0),\n",
       " ('Anabel', 8.0),\n",
       " ('Pedro', 5.0),\n",
       " ('Rocio', 6.0),\n",
       " ('Carlos', 4.0),\n",
       " ('Triana', 3.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b)\n",
    "notas_todas = notas_mates.union(notas_fisica).union(notas_ingles)\n",
    "notas_todas.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307eb58f-e7cd-40c8-8f34-8f953dae0627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Angel', 4.0),\n",
       " ('Carlos', 4.0),\n",
       " ('Anabel', 2.0),\n",
       " ('Jose Juan', 3.0),\n",
       " ('Jorge', 5.0),\n",
       " ('Susana', 2.0),\n",
       " ('Andres', 4.0),\n",
       " ('Fernando', 5.0),\n",
       " ('Oscar', 3.0),\n",
       " ('Isabel', 7.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "nota_min_por_alumno = notas_todas.reduceByKey(lambda a, b: a if a < b else b)\n",
    "nota_min_por_alumno.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84ca9b75-ee55-4d26-9367-a814c5a9632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Angel', 6.333333333333333),\n",
       " ('Carlos', 5.333333333333333),\n",
       " ('Anabel', 5.666666666666667),\n",
       " ('Jose Juan', 3.6666666666666665),\n",
       " ('Andres', 4.666666666666667),\n",
       " ('Jorge', 6.666666666666667),\n",
       " ('Susana', 6.666666666666667),\n",
       " ('Rocio', 5.5),\n",
       " ('Fernando', 7.0),\n",
       " ('Oscar', 5.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d)\n",
    "\n",
    "sum_count = notas_todas.combineByKey(\n",
    "    lambda nota: (nota, 1),                 # createCombiner\n",
    "    lambda acc, nota: (acc[0] + nota, acc[1] + 1),  # mergeValue\n",
    "    lambda a, b: (a[0] + b[0], a[1] + b[1])         # mergeCombiners\n",
    ")\n",
    "nota_media_por_alumno = sum_count.mapValues(lambda sc_: sc_[0] / sc_[1] if sc_[1] else 0.0)\n",
    "\n",
    "nota_media_por_alumno.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd47e7ef-5fab-4d29-b4d2-9ed65993aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudiantes que suspenden Matemáticas: 7\n",
      "Estudiantes que suspenden Física: 8\n",
      "Estudiantes que suspenden Inglés: 7\n",
      "[('mates', 7), ('fisica', 8), ('ingles', 7)]\n"
     ]
    }
   ],
   "source": [
    "# e)\n",
    "suspenden_mates = notas_mates.filter(lambda x: x[1] < 5).count()\n",
    "suspenden_fisica = notas_fisica.filter(lambda x: x[1] < 5).count()\n",
    "suspenden_ingles = notas_ingles.filter(lambda x: x[1] < 5).count()\n",
    "\n",
    "suspensos_por_asignatura = sc.parallelize([(\"mates\",suspenden_mates),(\"fisica\",suspenden_fisica),(\"ingles\",suspenden_ingles)])\n",
    "\n",
    "\n",
    "print(suspensos_por_asignatura.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fe1177-092d-471f-88fd-18ca9015ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mates', 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f)\n",
    "\n",
    "suspensos_por_asignatura.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32d6b4d5-bd02-4e15-8d47-9f600e88070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Carlos', (4.0, 4.0, 8.0)),\n",
       " ('Angel', (6.0, 9.0, 4.0)),\n",
       " ('Anabel', (8.0, 2.0, 7.0)),\n",
       " ('Jose Juan', (5.0, 3.0, 3.0)),\n",
       " ('Jorge', (10.0, 5.0, 5.0)),\n",
       " ('Susana', (9.0, 9.0, 2.0)),\n",
       " ('Andres', (4.0, 4.0, 6.0)),\n",
       " ('Rocio', (6.0, 5.0, 4.0)),\n",
       " ('Rocio', (6.0, 7.0, 4.0)),\n",
       " ('Fernando', (5.0, 9.0, 7.0)),\n",
       " ('Isabel', (8.0, 8.0, 7.0)),\n",
       " ('Alejandro', (5.0, 3.0, 7.0)),\n",
       " ('Oscar', (7.0, 5.0, 3.0)),\n",
       " ('Leonardo', (1.0, 6.0, 4.0)),\n",
       " ('Nicolas', (2.0, 7.0, 5.0)),\n",
       " ('Ramon', (4.5, 7.0, 8.0)),\n",
       " ('Maria', (2.0, 3.0, 6.0)),\n",
       " ('Triana', (3.0, 3.0, 4.0)),\n",
       " ('Rosa', (6.0, 8.0, 9.0))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g)\n",
    "rdd_total = notas_mates.join(notas_fisica).join(notas_ingles).mapValues(lambda t: (t[0][0], t[0][1], t[1]))\n",
    "rdd_total.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e66b4b-cbad-41ad-9b48-bc085b445af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
